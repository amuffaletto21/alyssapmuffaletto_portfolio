<html>
<body style=background-color:rgb(156, 238, 206)>
<head>
  <style>
  h1 {
    font-family: courier;
    color:rgb(107, 216, 231);
    text-align: center

  }
  div {
    display: flex;
    flex-direction: column;
    padding:15px;
    margin: 0 auto;
    border: 5px solid#69e9d2;
    border-radius: 5px;
    font-family:arial;
    color:rgb(123, 0, 138);
    background-color:rgb(203, 195, 233);
  }
  </style>
</head>
  <h1>Ethical Reflections </h1>
  <div class="machine">
    <h2>Ethical Reflection #1: Machine Bias</h2>
    <p>People everywhere are being wrongfully imprisoned everyday. While this may attribute to a false testimony from witnesses in court, or a misunderstanding, another probable cause for these incorrect arrests are biased algorithms. In many states around the country, these biased algorithms are the reason for illegitimate confinement, such as Wisconsin and Ohio. One of the algorithms that are used to determine how long someone should stay in custody for is called COMPAS (Correctional Offender Management Profiling for Alternative Sanctions). COMPAS has around 100 questions that are about quality of life, prior issues with the law, and much more that give courts more information about how long someone should stay in prison for and if they qualify for parole in the future, it indicates what type of help the parolee will need. This all seems great in theory, however, the system is flawed because it has a bias: against black people. In an article by<a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">ProPublica </a>, they covered the general facts of this issue, and in an article by <a href="https://www.technologyreview.com/s/607955/inspecting-algorithms-for-bias/MIT"> Technology Review</a>, they talked more about the issue and explained how and why the algorithms are biased by clarifying the system of “true positives.” True positives aren’t exactly used just to discover the high risk offenders, but also to find the most of these “high risk” repeat offenders. After reading both of these articles, this further solidifies my disappointment in this country and the way that it handles issues of race. These types of issues are hardly talked about in general in the media, even though this has such a huge impact on communities around the country and even the world. These types of algorithms shouldn’t be used to assess how many years a person should spend in prison and whether or not they will commit more crimes. Since the questions that are part of the algorithm are generic and only scrape the surface of a person’s life and can apply to most people of a certain group, they really should have no value in these types of decisions. Every person has a unique life story, and the details should be evaluated more heavily than simply the generalities of their situation. I believe that the system is inherently flawed already, even without the bias that the algorithms have, because the place that someone was raised, the type of people they hang out with, and most of all their race, should have no place in a decision of whether or not they should be arrested.
    </p>

    <h2>Ethical Reflection #2: Ad Dystopia </h2>
      <p>Millions, if not billions, of people all around the world go on the internet daily. This time could be spent online shopping, looking up a word you don’t know on Google, watching videos on YouTube and so much more. While on the internet, there is one thing in common that everyone will always come across: ads. These ads can market anything, from random things to products based on your browser history. The use of randomized ads doesn’t seem so bad, however the advertising based on personal data and information sounds quite invasive. I don’t normally think about the constant stream of ads that I get based off of my shopping cart on Amazon or Nike, but after referring to Zeynep Tufekci’s TED talk, and other resources, I’ve become more aware of this issue. Honestly, it isn’t the fact that companies market towards someone based on their internet shopping habits that’s a problem for me, because that’s more accessible and expected, it’s the other ways that corporations can advertise to someone in a more enticing way. However, I disagree with companies using information about your race, gender, sexuality, age, financial status, etc to make more money in advertising An example that Tufekci used in her TED talk were posts on Facebook about politics being catered towards a specific type of person without them even disclosing their opinions on their page. She also brought up a quote from Donald Trump’s social media manager during the election about how they posted, “Non public posts whose viewership the campaign controls so that only the people we want to see it see it. We modeled this. It will dramatically affect her ability to turn people out.” In this quote, the manager was referencing a series of dark posts that would have the effect of African American/Caribbean American/black men age 25-35 from voting at all. This is a blatant abuse of personalized ads for personal gain, and even though it is for a campaign, this is still extremely disgusting to read and hear about. In an article I found called “Ban Targeted Advertising” by David Dayen, he brings up another example of race influenced advertising. In the article, Dayen writes, “Advertisers armed with Big Data can ensure housing or employment advertisements don’t reach African-Americans or Hispanics, discriminating on the basis of race.” This was such a disappointing sentence to read because not only are these companies targeting people to scam them out of money or convince them not to vote, but these ads are also helping to perpetuate the cycle of poverty that occurs around the world for African Americans/Caribbean Americans/black and Latinx people. Based on this horrible use of personal data, I’m already against the use of this type of marketing. After reading another article entitled “Targeted Ads Don’t Just Make You More Likely to Buy-They Can Change How You Think About Yourself” by Rebecca Walker Reczek, Christopher Summers, and Robert Smith, I am somehow even more oppose to this method of advertisement. In this article, the authors discuss the ways that behavior influenced advertising can affect you both positively and negatively. For this they conducted an experiment with Harvard undergrads and either told them that their ads (all of which were the same) were based on internet activity or that it had nothing to do with browser history. The results of the experiment were that those that were told the advertisement was based on their behavior, they thought of themselves as more sophisticated because the ad was for an elegant restaurant. Those that weren’t told weren’t affected in any way by this. Even though people felt positive about themselves after, these types of behavior focussed ads can make people feel negatively about themselves.
      All in all, I am against the use of targeted advertisement because it almost always has a negative result for internet users.</p>
</html>
